services:
  ollama-server:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - /home/ai/ollama:/root/.ollama
      - /home/ai/code:/code
    environment:
      - APP_MAX_EXECUTION_TIME=3600
      - API_TOOL_DEFAULT_READ_TIMEOUT=3600
      - WORKFLOW_MAX_EXECUTION_TIME=3600
      - HTTP_REQUEST_MAX_CONNECT_TIMEOUT=3600
      - HTTP_REQUEST_MAX_READ_TIMEOUT=3600
      - HTTP_REQUEST_MAX_WRITE_TIMEOUT=3600

    restart: always
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: 1
            capabilities: [gpu]


  ollama-webui:
    image: ghcr.io/ollama-webui/ollama-webui:main
    container_name: ollama-webui
    restart: always
    volumes:
      - /home/ai/ollama-webui:/app/backend/data
    ports:
      - "3000:8080"
    environment:
      - '/ollama/api=http://ollama:11434/api'
    extra_hosts:
      - host.docker.internal:host-gateway